# 分布式改造

如果在线开发这种单机模式训练速度较慢，则需要把训练代码进行分布式化改造以利用平台分布式多机训练的功能。

## 改造指南

### Pytorch
可参考官方教程以及一些网络文章如https://zhuanlan.zhihu.com/p/178402798， 大部分情况下只需要调API即可。

**示例**：
将deeplabv3的单机训练代码进行分布式化后的主要变化为：

- 设置分布式训练任务之间的通信后端，推荐NCCL
  ```python
  if dist.is_available():
        parser.add_argument('--backend', type=str, help='Distributed backend',
                            choices=[dist.Backend.GLOO, dist.Backend.NCCL, dist.Backend.MPI],
                            default=dist.Backend.NCCL)
  ```
- 设置一些需要的环境变量
  ```python
  # env
WORLD_SIZE = int(os.environ.get('WORLD_SIZE', 1))
WORLD_RANK = int(os.environ.get('RANK'))
  ```

### Tensorflow